---
layout: page
title: About
permalink: /about/
---
<div align="justify">
My knowledge focus on various programming languages, but I’m working mostly with Python and SQL to
implement ETL processes, that depending on the amount of data, can run in one Worker or in a Spark
Cluster with many nodes. In this year I focused on distributed systems to process a huge amount of data, e.g.
Spark, but also distribute storages or SQL engines like Presto or ElasticSearch. I’m a big fan of AWS, and all
their services, why maintain a Kafka Cluster with ZooKeeper if you can easily setup a Kinesis Stream with
a flexible number of shards based on the number of producers? I like to maintain the AWS Infrastructure
using tools like Cloudformation or Teraform. This is not simply writing config files, but involves using tested
and proven software development practices e.g: version control, testing, small deployments, design patterns.
</div>

# Experience

### Data Engineer - [Babbel](https://home.babbel.com/)

<b>Period</b>: Oct 2015 - Now

*   Evolution of ETL pipelines from procedural SQL to Python/PySpark
*   Maintenance of the current ETL Pipeline
*   Maintaining and evolving the current AWS Infrastructure with Cloudformation
*   Data-visualization and reporting

### Junior Software Engineer - [eng.it](http://eng.it)

<b>Period</b>: Feb 2014 - Sep 2015

*   Data Warehouse design (Dimensional Model/Star schema)
*   Getting and cleaning data with process of Extract-Transform-Load (ETL)
*   KPIs design
*   Data-visualization and reporting
*   Maintenance and administration of the BI Suite [SpagoBI](https://www.spagobi.org/)

### Student Software Developer - [TU Berlin/T-Labs](http://www.laboratories.telekom.com/)

<b>Period</b>: May 2013 - Aug 2013

*   Implementation of an extension of a web-based data visualization tool for IPTV QoE Reports
*   KQI (Key Quality Index) design and implementation
*   KQI visualization for specific days and for specific locations
